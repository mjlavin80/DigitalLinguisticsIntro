{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very first code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, world!\n"
     ]
    }
   ],
   "source": [
    "print(\"hello, world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The string type\n",
    "String type objects are enclosed in quotation marks. \n",
    "\n",
    "\\+ is a concatenation operator.\n",
    "\n",
    "Below, `greet` is a variable name assigned to a string value; note the absence of quotation marks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello, world! here I come'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greet = \"hello, world!\"\n",
    "greet + \" here I come\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String methods such as .upper(), .lower() transform a string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HELLO, WORLD!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greet.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`len()` is a handy function that returns the length of a string in the # of characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(greet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numbers\n",
    "Integers and floats are written without quotes. \n",
    "\n",
    "You can use algebraic operations such as `+`, `-`, `*` and `/` with numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3141.592"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1 = 5678\n",
    "num2 = 3.141592\n",
    "num2 * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditionals\n",
    "Python is famous for marking conditional blocks with indentation. The colon `:` signals the beginning of code block. \n",
    "\n",
    "`if condition1 ... elif condition2 ... else`\n",
    "\n",
    "is how Python conditionals are structured. The `elif` and `else` block are optional.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium-length word.\n"
     ]
    }
   ],
   "source": [
    "word = 'hippopotamus'\n",
    "if len(word) > 13 :\n",
    "    print(\"That is a long word.\")\n",
    "elif len(word) > 5 :\n",
    "    print(\"Medium-length word.\")\n",
    "else :\n",
    "    print(\"Short and sweet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists\n",
    "Lists are enclosed in `[ ]`, with elements separated with commas. Lists can have strings, numbers, and more. \n",
    "\n",
    "Like with string, you can use `len()` and also `+` with lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = ['red', 'blue', 'green', 'black', 'white', 'pink']\n",
    "len(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red', 'blue', 'green', 'black', 'white', 'pink', 'orange', 'red', 'yellow']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li2 = ['orange', 'red', 'yellow']\n",
    "li + li2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"in\" operator\n",
    "`in` can be used with strings or lists. \n",
    "\n",
    "With strings, it tests for substring-hood. \n",
    "\n",
    "With lists, it tests if an element is found in the list. \n",
    "\n",
    "`not` is the negation operator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'p' in word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'orange' not in li2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List comprehension\n",
    "List comprehension is magic.\n",
    "Try: `.upper()`, `len()`, `+'ish'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['black', 'pink']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in li if 'e' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['redish', 'blueish', 'greenish', 'blackish', 'whiteish', 'pinkish']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x + 'ish' for x in li]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using NLTK\n",
    "NLTK is an external module; you can start using it after importing it. \n",
    "\n",
    "`nltk.word_tokenize()` is a handy tokenizing function out of literally tons of functions it provides.\n",
    "\n",
    "It turns a text (a single string) into a list tokenized words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', ',', 'world', '!']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(greet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It', \"'s\", '5', \"o'clock\", 'somewhere', '...', '!', '!']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"It's 5 o'clock somewhere...!!\"\n",
    "nltk.word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nltk.FreqDist()` builds a frequency dictionary from a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'rose', 'is', 'a', 'rose', 'is', 'a', 'rose', 'is', 'a', 'rose', '.']\n"
     ]
    }
   ],
   "source": [
    "sent = 'A rose is a rose is a rose is a rose.'\n",
    "toks = nltk.word_tokenize(sent.lower())\n",
    "print(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'.': 1, 'a': 4, 'is': 3, 'rose': 4})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = nltk.FreqDist(toks)\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 4), ('rose', 4), ('is', 3)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq['rose']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in a text file\n",
    "`open(filename).read()` reads in the content of a text file as a single string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I agree greatly this topic mainly because I think that English becomes an official language in the not too distant. Now, many people can speak English or study it all over the world, and so more people will be able to speak English. Before the Japanese fall behind other people, we should be able to speak English, therefore, we must study English not only junior high school students or over but also pupils. Japanese education system is changing such a program. In this way, Japan tries to internationalize rapidly. However, I think this way won't suffice for becoming international humans. To becoming international humans, we should study English not only school but also daily life. If we can do it, we are able to master English conversation. It is important for us to master English honorific words. Without speaking English honorific, we can't speak English. If we speak English without it, it is rude of you, and so we should master proper English. Therefore, we should learn even our daily life.\n",
      "I have not only mainly reason but also some partly reason. First partly reason is that if we speak English, we can get though to almost people all over the world, ant it is wonderful for me. Because I am able to make for good humun natures, if I can communicate with others who lives in foreign country. These reasons is worth reason why I must study English. By contraries, if we can't speak English, we can communicate with only people who speak Japanese. It is terrible for me, because we can't keep up with the development of the world. So not only adults but also Japanese students need to master English as a second language.\n",
      "Second reason is theta people who visit in Japan from another country increase gradually, that is to say, the opportunity to talk to the foreigners increase gradually without notice, so Japanese people should be able to speak an introduction to English conversation, and I hope that, and I wish all Japanese people could be beyond the boundary to all foreigners, but it is the actual circumstances to be able to talk foreigners only partial Japanese people. Therefore, as time went on, the Japanese people should be able to talk them, and the Japanese people who get out into the world should be able to talk them, too.\n",
      "I agree greatly to need to master English as a second language for Japanese people, and I am certain of that.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myfile = 'corpus/JPSW1001.txt'\n",
    "essay = open(myfile).read()\n",
    "print(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2368"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'I am certain' in essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'agree',\n",
       " 'greatly',\n",
       " 'this',\n",
       " 'topic',\n",
       " 'mainly',\n",
       " 'because',\n",
       " 'I',\n",
       " 'think',\n",
       " 'that',\n",
       " 'English',\n",
       " 'becomes',\n",
       " 'an',\n",
       " 'official',\n",
       " 'language',\n",
       " 'in',\n",
       " 'the',\n",
       " 'not',\n",
       " 'too',\n",
       " 'distant',\n",
       " '.',\n",
       " 'Now',\n",
       " ',',\n",
       " 'many',\n",
       " 'people',\n",
       " 'can',\n",
       " 'speak',\n",
       " 'English',\n",
       " 'or',\n",
       " 'study',\n",
       " 'it',\n",
       " 'all',\n",
       " 'over',\n",
       " 'the',\n",
       " 'world',\n",
       " ',',\n",
       " 'and',\n",
       " 'so',\n",
       " 'more',\n",
       " 'people',\n",
       " 'will',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'speak',\n",
       " 'English',\n",
       " '.',\n",
       " 'Before',\n",
       " 'the',\n",
       " 'Japanese',\n",
       " 'fall',\n",
       " 'behind',\n",
       " 'other',\n",
       " 'people',\n",
       " ',',\n",
       " 'we',\n",
       " 'should',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'speak',\n",
       " 'English',\n",
       " ',',\n",
       " 'therefore',\n",
       " ',',\n",
       " 'we',\n",
       " 'must',\n",
       " 'study',\n",
       " 'English',\n",
       " 'not',\n",
       " 'only',\n",
       " 'junior',\n",
       " 'high',\n",
       " 'school',\n",
       " 'students',\n",
       " 'or',\n",
       " 'over',\n",
       " 'but',\n",
       " 'also',\n",
       " 'pupils',\n",
       " '.',\n",
       " 'Japanese',\n",
       " 'education',\n",
       " 'system',\n",
       " 'is',\n",
       " 'changing',\n",
       " 'such',\n",
       " 'a',\n",
       " 'program',\n",
       " '.',\n",
       " 'In',\n",
       " 'this',\n",
       " 'way',\n",
       " ',',\n",
       " 'Japan',\n",
       " 'tries',\n",
       " 'to',\n",
       " 'internationalize',\n",
       " 'rapidly',\n",
       " '.',\n",
       " 'However',\n",
       " ',',\n",
       " 'I',\n",
       " 'think',\n",
       " 'this',\n",
       " 'way',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'suffice',\n",
       " 'for',\n",
       " 'becoming',\n",
       " 'international',\n",
       " 'humans',\n",
       " '.',\n",
       " 'To',\n",
       " 'becoming',\n",
       " 'international',\n",
       " 'humans',\n",
       " ',',\n",
       " 'we',\n",
       " 'should',\n",
       " 'study',\n",
       " 'English',\n",
       " 'not',\n",
       " 'only',\n",
       " 'school',\n",
       " 'but',\n",
       " 'also',\n",
       " 'daily',\n",
       " 'life',\n",
       " '.',\n",
       " 'If',\n",
       " 'we',\n",
       " 'can',\n",
       " 'do',\n",
       " 'it',\n",
       " ',',\n",
       " 'we',\n",
       " 'are',\n",
       " 'able',\n",
       " 'to',\n",
       " 'master',\n",
       " 'English',\n",
       " 'conversation',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'important',\n",
       " 'for',\n",
       " 'us',\n",
       " 'to',\n",
       " 'master',\n",
       " 'English',\n",
       " 'honorific',\n",
       " 'words',\n",
       " '.',\n",
       " 'Without',\n",
       " 'speaking',\n",
       " 'English',\n",
       " 'honorific',\n",
       " ',',\n",
       " 'we',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'speak',\n",
       " 'English',\n",
       " '.',\n",
       " 'If',\n",
       " 'we',\n",
       " 'speak',\n",
       " 'English',\n",
       " 'without',\n",
       " 'it',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'rude',\n",
       " 'of',\n",
       " 'you',\n",
       " ',',\n",
       " 'and',\n",
       " 'so',\n",
       " 'we',\n",
       " 'should',\n",
       " 'master',\n",
       " 'proper',\n",
       " 'English',\n",
       " '.',\n",
       " 'Therefore',\n",
       " ',',\n",
       " 'we',\n",
       " 'should',\n",
       " 'learn',\n",
       " 'even',\n",
       " 'our',\n",
       " 'daily',\n",
       " 'life',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'not',\n",
       " 'only',\n",
       " 'mainly',\n",
       " 'reason',\n",
       " 'but',\n",
       " 'also',\n",
       " 'some',\n",
       " 'partly',\n",
       " 'reason',\n",
       " '.',\n",
       " 'First',\n",
       " 'partly',\n",
       " 'reason',\n",
       " 'is',\n",
       " 'that',\n",
       " 'if',\n",
       " 'we',\n",
       " 'speak',\n",
       " 'English',\n",
       " ',',\n",
       " 'we',\n",
       " 'can',\n",
       " 'get',\n",
       " 'though',\n",
       " 'to',\n",
       " 'almost',\n",
       " 'people',\n",
       " 'all',\n",
       " 'over',\n",
       " 'the',\n",
       " 'world',\n",
       " ',',\n",
       " 'ant',\n",
       " 'it',\n",
       " 'is',\n",
       " 'wonderful',\n",
       " 'for',\n",
       " 'me',\n",
       " '.',\n",
       " 'Because',\n",
       " 'I',\n",
       " 'am',\n",
       " 'able',\n",
       " 'to',\n",
       " 'make',\n",
       " 'for',\n",
       " 'good',\n",
       " 'humun',\n",
       " 'natures',\n",
       " ',',\n",
       " 'if',\n",
       " 'I',\n",
       " 'can',\n",
       " 'communicate',\n",
       " 'with',\n",
       " 'others',\n",
       " 'who',\n",
       " 'lives',\n",
       " 'in',\n",
       " 'foreign',\n",
       " 'country',\n",
       " '.',\n",
       " 'These',\n",
       " 'reasons',\n",
       " 'is',\n",
       " 'worth',\n",
       " 'reason',\n",
       " 'why',\n",
       " 'I',\n",
       " 'must',\n",
       " 'study',\n",
       " 'English',\n",
       " '.',\n",
       " 'By',\n",
       " 'contraries',\n",
       " ',',\n",
       " 'if',\n",
       " 'we',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'speak',\n",
       " 'English',\n",
       " ',',\n",
       " 'we',\n",
       " 'can',\n",
       " 'communicate',\n",
       " 'with',\n",
       " 'only',\n",
       " 'people',\n",
       " 'who',\n",
       " 'speak',\n",
       " 'Japanese',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'terrible',\n",
       " 'for',\n",
       " 'me',\n",
       " ',',\n",
       " 'because',\n",
       " 'we',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'keep',\n",
       " 'up',\n",
       " 'with',\n",
       " 'the',\n",
       " 'development',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'So',\n",
       " 'not',\n",
       " 'only',\n",
       " 'adults',\n",
       " 'but',\n",
       " 'also',\n",
       " 'Japanese',\n",
       " 'students',\n",
       " 'need',\n",
       " 'to',\n",
       " 'master',\n",
       " 'English',\n",
       " 'as',\n",
       " 'a',\n",
       " 'second',\n",
       " 'language',\n",
       " '.',\n",
       " 'Second',\n",
       " 'reason',\n",
       " 'is',\n",
       " 'theta',\n",
       " 'people',\n",
       " 'who',\n",
       " 'visit',\n",
       " 'in',\n",
       " 'Japan',\n",
       " 'from',\n",
       " 'another',\n",
       " 'country',\n",
       " 'increase',\n",
       " 'gradually',\n",
       " ',',\n",
       " 'that',\n",
       " 'is',\n",
       " 'to',\n",
       " 'say',\n",
       " ',',\n",
       " 'the',\n",
       " 'opportunity',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'to',\n",
       " 'the',\n",
       " 'foreigners',\n",
       " 'increase',\n",
       " 'gradually',\n",
       " 'without',\n",
       " 'notice',\n",
       " ',',\n",
       " 'so',\n",
       " 'Japanese',\n",
       " 'people',\n",
       " 'should',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'speak',\n",
       " 'an',\n",
       " 'introduction',\n",
       " 'to',\n",
       " 'English',\n",
       " 'conversation',\n",
       " ',',\n",
       " 'and',\n",
       " 'I',\n",
       " 'hope',\n",
       " 'that',\n",
       " ',',\n",
       " 'and',\n",
       " 'I',\n",
       " 'wish',\n",
       " 'all',\n",
       " 'Japanese',\n",
       " 'people',\n",
       " 'could',\n",
       " 'be',\n",
       " 'beyond',\n",
       " 'the',\n",
       " 'boundary',\n",
       " 'to',\n",
       " 'all',\n",
       " 'foreigners',\n",
       " ',',\n",
       " 'but',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'actual',\n",
       " 'circumstances',\n",
       " 'to',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'foreigners',\n",
       " 'only',\n",
       " 'partial',\n",
       " 'Japanese',\n",
       " 'people',\n",
       " '.',\n",
       " 'Therefore',\n",
       " ',',\n",
       " 'as',\n",
       " 'time',\n",
       " 'went',\n",
       " 'on',\n",
       " ',',\n",
       " 'the',\n",
       " 'Japanese',\n",
       " 'people',\n",
       " 'should',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'them',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Japanese',\n",
       " 'people',\n",
       " 'who',\n",
       " 'get',\n",
       " 'out',\n",
       " 'into',\n",
       " 'the',\n",
       " 'world',\n",
       " 'should',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'them',\n",
       " ',',\n",
       " 'too',\n",
       " '.',\n",
       " 'I',\n",
       " 'agree',\n",
       " 'greatly',\n",
       " 'to',\n",
       " 'need',\n",
       " 'to',\n",
       " 'master',\n",
       " 'English',\n",
       " 'as',\n",
       " 'a',\n",
       " 'second',\n",
       " 'language',\n",
       " 'for',\n",
       " 'Japanese',\n",
       " 'people',\n",
       " ',',\n",
       " 'and',\n",
       " 'I',\n",
       " 'am',\n",
       " 'certain',\n",
       " 'of',\n",
       " 'that',\n",
       " '.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens = nltk.word_tokenize(essay)\n",
    "len(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 30),\n",
       " ('.', 22),\n",
       " ('to', 20),\n",
       " ('English', 18),\n",
       " ('we', 14),\n",
       " ('the', 13),\n",
       " ('people', 12),\n",
       " ('I', 11),\n",
       " ('is', 10),\n",
       " ('Japanese', 10)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = nltk.FreqDist(word_tokens)\n",
    "word_freq.most_common(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
